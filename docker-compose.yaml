
services:
  # Schema Registry Application with Embedded NATS
  schema-registry:
    build: 
      context: .
      dockerfile: Dockerfile
    container_name: schema-registry
    hostname: schema-registry
    ports:
      - "8080:8080"  # HTTP API
      - "4222:4222"  # NATS Client Port
      - "8222:8222"  # NATS Monitoring
    environment:
      # NATS Embedded Configuration
      - NATS_SERVER_NAME=schema-registry-embedded
      - NATS_STORE_DIR=/data/jetstream
      - NATS_HOST=0.0.0.0
      - NATS_PORT=4222
      - NATS_HTTP_PORT=8222
      
      # Application Configuration
      - HTTP_PORT=:8080
      - APP_VERSION=1.0.0
      
      # Observability Configuration
      - METRICS_ENABLED=true
      - METRICS_PATH=/metrics
      - LOG_LEVEL=info
      - LOG_FORMAT=json
      
      # Compatibility Configuration
      - COMPATIBILITY_LEVEL=BACKWARD
      
      # Development
      - DEBUG=false
    volumes:
      - schema_registry_data:/data
      - ./logs:/app/logs
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    networks:
      - monitoring
    labels:
      - "prometheus.job=schema-registry-app"
      - "prometheus.port=8080"
      - "prometheus.path=/metrics"

  # Prometheus - Metrics Collection
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    hostname: prometheus
    ports:
      - "9090:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-remote-write-receiver'
      - '--enable-feature=exemplar-storage'
      - '--enable-feature=memory-snapshot-on-shutdown'
    volumes:
      - prometheus_data:/prometheus
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/alerts.yml:/etc/prometheus/alerts.yml:ro
      - ./monitoring/prometheus-rules.yml:/etc/prometheus/rules.yml:ro
    environment:
      - PROMETHEUS_LOG_LEVEL=info
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - monitoring
    depends_on:
      - schema-registry

  # Grafana - Dashboards and Visualization
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    hostname: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin123
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
      - GF_FEATURE_TOGGLES_ENABLE=publicDashboards
      - GF_ANALYTICS_REPORTING_ENABLED=false
      - GF_LOG_MODE=console
      - GF_LOG_LEVEL=info
    volumes:
      - grafana_data:/var/lib/grafana
      - ./config/grafana-datasource.yml:/etc/grafana/provisioning/datasources/datasource.yml:ro
      - ./monitoring/grafana-dashboard.yml:/etc/grafana/provisioning/dashboards/dashboard.yml:ro
      - ./monitoring/dashboard.json:/etc/grafana/provisioning/dashboards/schema-registry.json:ro
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - monitoring
    depends_on:
      - prometheus

  # Alertmanager - Alert Management
  alertmanager:
    image: prom/alertmanager:latest
    container_name: alertmanager
    hostname: alertmanager
    ports:
      - "9093:9093"
      - "9094:9094"  # Cluster port
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--cluster.advertise-address=0.0.0.0:9094'
      - '--web.external-url=http://localhost:9093'
    volumes:
      - alertmanager_data:/alertmanager
      - ./monitoring/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
    environment:
      - LOG_LEVEL=info
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9093/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - monitoring
    depends_on:
      - prometheus

  # Node Exporter - System Metrics
  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    hostname: node-exporter
    ports:
      - "9100:9100"
    command:
      - '--path.rootfs=/host'
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
      - '--collector.textfile.directory=/etc/node-exporter/'
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    restart: unless-stopped
    networks:
      - monitoring
    labels:
      - "prometheus.job=node-exporter"

  # cAdvisor - Container Metrics
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    hostname: cadvisor
    ports:
      - "8088:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    devices:
      - /dev/kmsg
    privileged: true
    restart: unless-stopped
    networks:
      - monitoring
    labels:
      - "prometheus.job=cadvisor"

  # Redis - Optional: for caching (if needed)
  redis:
    image: redis:7-alpine
    container_name: redis
    hostname: redis
    ports:
      - "6379:6379"
    command: 
      - redis-server
      - --appendonly yes
      - --maxmemory 256mb
      - --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - monitoring

  # Loki - Log Aggregation
  loki:
    image: grafana/loki:latest
    container_name: loki
    hostname: loki
    ports:
      - "3100:3100"
    command: 
      - -config.file=/etc/loki/local-config.yaml
    volumes:
      - loki_data:/loki
      - ./monitoring/loki-config.yml:/etc/loki/local-config.yaml:ro
    restart: unless-stopped
    networks:
      - monitoring

  # Promtail - Log Collection
  promtail:
    image: grafana/promtail:latest
    container_name: promtail
    hostname: promtail
    volumes:
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - ./monitoring/promtail-config.yml:/etc/promtail/config.yml:ro
    command: 
      - -config.file=/etc/promtail/config.yml
    restart: unless-stopped
    networks:
      - monitoring
    depends_on:
      - loki

  # Jaeger - Distributed Tracing (Optional)
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: jaeger
    hostname: jaeger
    ports:
      - "16686:16686"  # UI
      - "14268:14268"  # Collector
      - "14250:14250"  # GRPC
    environment:
      - COLLECTOR_OTLP_ENABLED=true
      - LOG_LEVEL=debug
    restart: unless-stopped
    networks:
      - monitoring

  # Test Client - For API testing
  test-client:
    image: curlimages/curl:latest
    container_name: test-client
    hostname: test-client
    volumes:
      - ./scripts:/scripts
    working_dir: /scripts
    command: 
      - sh
      - -c
      - |
        echo "ðŸš€ Waiting for schema-registry to be ready..."
        until curl -s http://schema-registry:8080/health > /dev/null; do
          sleep 5
        done
        echo "âœ… Schema Registry is ready!"
        echo "ðŸ“‹ Running API tests..."
        ./api-test.sh
        sleep infinity
    restart: on-failure
    networks:
      - monitoring
    depends_on:
      - schema-registry

  # Portainer - Container Management (Optional)
  portainer:
    image: portainer/portainer-ce:latest
    container_name: portainer
    hostname: portainer
    ports:
      - "9000:9000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - portainer_data:/data
    restart: unless-stopped
    networks:
      - monitoring

volumes:
  schema_registry_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  alertmanager_data:
    driver: local
  redis_data:
    driver: local
  loki_data:
    driver: local
  portainer_data:
    driver: local

networks:
  monitoring:
    driver: bridge
    ipam:
      config:
        - subnet: 172.30.0.0/16